{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e3f0666",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "import nltk\n",
    "# from nltk import word_tokenize - нужно nltk.download('punkt')\n",
    "\n",
    "from nltk import wordpunct_tokenize, wordnet\n",
    "from nltk.stem import wordnet as WordNetLem\n",
    "from nltk.stem import SnowballStemmer, StemmerI\n",
    "\n",
    "import gensim\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "d7b11695",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = \\\n",
    "    []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d4bce7",
   "metadata": {},
   "source": [
    "# Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec2dec68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/coffee.csv')\n",
    "df['rating'] = df['rating'].astype('float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "e405e479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 5)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tmp = df.iloc[:500]\n",
    "df_tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "cf97bcd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Положительное место с хорошими блюдами , только персонал отличился высокомерием и надменностью, не рекомендую к посещению, останется неприятный осадок \\n'"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tmp['text'].iloc[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f35a6a",
   "metadata": {},
   "source": [
    "# Предобработка данных \n",
    "- токенизация gensim, потому что там без пунктуации получается\n",
    "- стемминг/лемматизация\n",
    "- удаление стоп слов\n",
    "- создание би/три-грамм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "76415f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# лемматизация\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "cfb577b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['удобное',\n",
       " 'расположение',\n",
       " 'работает',\n",
       " 'круглосуточно',\n",
       " 'внутри',\n",
       " 'очень',\n",
       " 'мало',\n",
       " 'места',\n",
       " 'туалет',\n",
       " 'так',\n",
       " 'себе',\n",
       " 'но',\n",
       " 'выбор',\n",
       " 'шаверм',\n",
       " 'их',\n",
       " 'вкус',\n",
       " 'покрывает',\n",
       " 'все',\n",
       " 'недостатки']"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = list(sent_to_words(df_tmp['text']))\n",
    "tokens[5][:32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "01762520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['пил',\n",
       " 'коф',\n",
       " 'рим',\n",
       " 'париж',\n",
       " 'вкусн',\n",
       " 'капуч',\n",
       " 'фундучн',\n",
       " 'молок',\n",
       " 'фирмен',\n",
       " 'сливк',\n",
       " 'джинж',\n",
       " 'пробова',\n",
       " 'десерт',\n",
       " 'очен',\n",
       " 'необычн',\n",
       " 'ребят',\n",
       " 'барист',\n",
       " 'больш',\n",
       " 'молодц',\n",
       " 'нчто',\n",
       " 'улучш',\n",
       " 'маловат',\n",
       " 'мест',\n",
       " 'посадко',\n",
       " 'придума']"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# стемминг и удаление стоп слов\n",
    "stemmer = SnowballStemmer('russian')\n",
    "\n",
    "stem_nltk = []\n",
    "for sentence in tokens:\n",
    "    stem_nltk.append(list(stemmer.stem(word_x) for word_x in sentence if word_x not in stop_words))\n",
    "stem_nltk[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9b01ac",
   "metadata": {},
   "source": [
    "# Кодирование текста\n",
    "- CountVectorizer\n",
    "- CountVectorizer(binary=True)\n",
    "- Tfidf\n",
    "- Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "45f33b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding_frequency = CountVectorizer(analyzer='word',\n",
    "#                                    # binary=True,\n",
    "#                                    min_df=2,          # минимальное количество вхождений слова\n",
    "#                                    ngram_range=(2,3),   # какие n-граммы учитывать\n",
    "#                                    #stop_words=stopwords.words(\"russian\")\n",
    "#                                   )\n",
    "\n",
    "\n",
    "# coding_tfidf = TfidfVectorizer(# min_df=2,          # минимальное количество вхождений слова\n",
    "#                                 ngram_range=(2,3),   # какие n-граммы учитывать\n",
    "#                                 #stop_words=stopwords.words(\"russian\")\n",
    "#                                 )\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "17c5d4fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00506188,  0.01428302,  0.00100153, -0.01065414, -0.00283817,\n",
       "        0.0035261 , -0.01456202,  0.00311686, -0.01392682,  0.01010637,\n",
       "        0.00846607,  0.01304028, -0.01377159,  0.01310898, -0.0103531 ,\n",
       "        0.0023483 , -0.0076668 ,  0.00474966,  0.0120494 , -0.00812947,\n",
       "       -0.00716008,  0.0026629 ,  0.01313637, -0.01159228, -0.0071721 ,\n",
       "        0.01278654, -0.01153663, -0.01072278, -0.0152599 ,  0.01348103],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Для обучения модели нам нужен список целевых документов\n",
    "def tagged_document(list_of_ListOfWords):\n",
    "    for x, ListOfWords in enumerate(list_of_ListOfWords):\n",
    "        yield doc2vec.TaggedDocument(ListOfWords, [x])\n",
    "\n",
    "# Обновите модель\n",
    "\n",
    "# Инициализация модели\n",
    "d2v_model = doc2vec.Doc2Vec(vector_size=30, # длина вектора, которым будет представлено предложение\n",
    "                            min_count=2,    # min кол-во встречания слова в прпедложении для учета\n",
    "                            epochs=30,      # количество эпох\n",
    "                           )\n",
    "# новые данные\n",
    "data_new = list(tagged_document(stem_nltk))\n",
    "    \n",
    "# расширить словарный запас\n",
    "d2v_model.build_vocab(data_new)\n",
    "  \n",
    "# Обучение модели Doc2Vec\n",
    "d2v_model.train(data_new, total_examples=d2v_model.corpus_count, epochs=d2v_model.epochs)\n",
    "  \n",
    "# Анализ выходных данных\n",
    "analyze = d2v_model.infer_vector(['Мама мыла раму'])\n",
    "analyze    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e24d92bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'глубинк стран во всех сво проявлен ассортимент столовск интерьер качеств цен приемлем для средн бюджетно столово ссср не все чист все не нов что бы вы хотел на трасс поел желудок не бастова знач риск был оправда номер для ночлег аналогичн толк пластиков окн нормальн не закр штор на окн нет тольк тюл для перв этаж плох мал ли кто заглядыва туалет душ совок но повтор для трасс да за руб соидет'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_stem_text = []\n",
    "for word_x in range(len(stem_nltk)):\n",
    "    tok_stem_text.append(\" \".join(stem_nltk[word_x]))\n",
    "tok_stem_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8b95636d",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec_vectorizer = np.array([d2v_model.infer_vector([text_x]) for text_x in tok_stem_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2d700f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "17b4719d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scal = MinMaxScaler()\n",
    "doc2vec_vectorizer = scal.fit_transform(doc2vec_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bede5900",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_vectorizer = coding_tfidf.fit_transform(tok_stem_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "88216b8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>глубинк стран</th>\n",
       "      <th>стран во</th>\n",
       "      <th>во всех</th>\n",
       "      <th>всех сво</th>\n",
       "      <th>сво проявлен</th>\n",
       "      <th>проявлен ассортимент</th>\n",
       "      <th>ассортимент столовск</th>\n",
       "      <th>столовск интерьер</th>\n",
       "      <th>интерьер качеств</th>\n",
       "      <th>качеств цен</th>\n",
       "      <th>...</th>\n",
       "      <th>посл прохожден магазин</th>\n",
       "      <th>прохожден магазин за</th>\n",
       "      <th>магазин за покупк</th>\n",
       "      <th>за покупк заход</th>\n",
       "      <th>покупк заход эт</th>\n",
       "      <th>заход эт каф</th>\n",
       "      <th>эт каф заход</th>\n",
       "      <th>каф заход убед</th>\n",
       "      <th>заход убед вам</th>\n",
       "      <th>убед вам понрав</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 30343 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     глубинк стран  стран во  во всех  всех сво  сво проявлен  \\\n",
       "0              0.0       0.0      0.0       0.0           0.0   \n",
       "1              0.0       0.0      0.0       0.0           0.0   \n",
       "2              0.0       0.0      0.0       0.0           0.0   \n",
       "3              0.0       0.0      0.0       0.0           0.0   \n",
       "4              0.0       0.0      0.0       0.0           0.0   \n",
       "..             ...       ...      ...       ...           ...   \n",
       "495            0.0       0.0      0.0       0.0           0.0   \n",
       "496            0.0       0.0      0.0       0.0           0.0   \n",
       "497            0.0       0.0      0.0       0.0           0.0   \n",
       "498            0.0       0.0      0.0       0.0           0.0   \n",
       "499            0.0       0.0      0.0       0.0           0.0   \n",
       "\n",
       "     проявлен ассортимент  ассортимент столовск  столовск интерьер  \\\n",
       "0                     0.0                   0.0                0.0   \n",
       "1                     0.0                   0.0                0.0   \n",
       "2                     0.0                   0.0                0.0   \n",
       "3                     0.0                   0.0                0.0   \n",
       "4                     0.0                   0.0                0.0   \n",
       "..                    ...                   ...                ...   \n",
       "495                   0.0                   0.0                0.0   \n",
       "496                   0.0                   0.0                0.0   \n",
       "497                   0.0                   0.0                0.0   \n",
       "498                   0.0                   0.0                0.0   \n",
       "499                   0.0                   0.0                0.0   \n",
       "\n",
       "     интерьер качеств  качеств цен  ...  посл прохожден магазин  \\\n",
       "0                 0.0          0.0  ...                     0.0   \n",
       "1                 0.0          0.0  ...                     0.0   \n",
       "2                 0.0          0.0  ...                     0.0   \n",
       "3                 0.0          0.0  ...                     0.0   \n",
       "4                 0.0          0.0  ...                     0.0   \n",
       "..                ...          ...  ...                     ...   \n",
       "495               0.0          0.0  ...                     0.0   \n",
       "496               0.0          0.0  ...                     0.0   \n",
       "497               0.0          0.0  ...                     0.0   \n",
       "498               0.0          0.0  ...                     0.0   \n",
       "499               0.0          0.0  ...                     0.0   \n",
       "\n",
       "     прохожден магазин за  магазин за покупк  за покупк заход  \\\n",
       "0                     0.0                0.0              0.0   \n",
       "1                     0.0                0.0              0.0   \n",
       "2                     0.0                0.0              0.0   \n",
       "3                     0.0                0.0              0.0   \n",
       "4                     0.0                0.0              0.0   \n",
       "..                    ...                ...              ...   \n",
       "495                   0.0                0.0              0.0   \n",
       "496                   0.0                0.0              0.0   \n",
       "497                   0.0                0.0              0.0   \n",
       "498                   0.0                0.0              0.0   \n",
       "499                   0.0                0.0              0.0   \n",
       "\n",
       "     покупк заход эт  заход эт каф  эт каф заход  каф заход убед  \\\n",
       "0                0.0           0.0           0.0             0.0   \n",
       "1                0.0           0.0           0.0             0.0   \n",
       "2                0.0           0.0           0.0             0.0   \n",
       "3                0.0           0.0           0.0             0.0   \n",
       "4                0.0           0.0           0.0             0.0   \n",
       "..               ...           ...           ...             ...   \n",
       "495              0.0           0.0           0.0             0.0   \n",
       "496              0.0           0.0           0.0             0.0   \n",
       "497              0.0           0.0           0.0             0.0   \n",
       "498              0.0           0.0           0.0             0.0   \n",
       "499              0.0           0.0           0.0             0.0   \n",
       "\n",
       "     заход убед вам  убед вам понрав  \n",
       "0               0.0              0.0  \n",
       "1               0.0              0.0  \n",
       "2               0.0              0.0  \n",
       "3               0.0              0.0  \n",
       "4               0.0              0.0  \n",
       "..              ...              ...  \n",
       "495             0.0              0.0  \n",
       "496             0.0              0.0  \n",
       "497             0.0              0.0  \n",
       "498             0.0              0.0  \n",
       "499             0.0              0.0  \n",
       "\n",
       "[500 rows x 30343 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# таблица частоты слов\n",
    "pd.DataFrame(res_vectorizer.toarray(), columns = coding_tfidf.vocabulary_.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb50c92f",
   "metadata": {},
   "source": [
    "# Моделирование\n",
    "- LDA sklearn\n",
    "- LDA gensim\n",
    "- LSI sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e465e9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LatentDirichletAllocation(n_components=5,   # количество тем\n",
    "                                  #learning_method='online',\n",
    "                                  random_state=42,\n",
    "                                  n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9d10367e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(n_components=5, n_jobs=-1, random_state=42)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(doc2vec_vectorizer)   # принимает результат CountVectorizer и аналогичные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0e3eba77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity 2634.328178659377\n",
      "Log Likelihood -36940.238464014314\n"
     ]
    }
   ],
   "source": [
    "print(\"Perplexity\", model.perplexity(res_vectorizer))\n",
    "print(\"Log Likelihood\", model.score(res_vectorizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a700b1ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity 40.0481816580527\n",
      "Log Likelihood -27659.74708201889\n"
     ]
    }
   ],
   "source": [
    "print(\"Perplexity\", model.perplexity(doc2vec_vectorizer))\n",
    "print(\"Log Likelihood\", model.score(doc2vec_vectorizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "236481e7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      2\n",
       "1      5\n",
       "2      2\n",
       "3      1\n",
       "4      5\n",
       "      ..\n",
       "495    5\n",
       "496    2\n",
       "497    4\n",
       "498    5\n",
       "499    4\n",
       "Length: 500, dtype: object"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame(model.transform(doc2vec_vectorizer), columns=[str(i) for i in range(1, 6)])\n",
    "thems = result.apply(lambda x: x.sort_values().index[-1], axis=1)\n",
    "thems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e14f7ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       True\n",
       "1      False\n",
       "2       True\n",
       "3      False\n",
       "4      False\n",
       "       ...  \n",
       "495    False\n",
       "496     True\n",
       "497    False\n",
       "498    False\n",
       "499    False\n",
       "Length: 500, dtype: bool"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thems == '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "36bbce0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Глубинка страны во всех своих проявлениях. Асс...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Не очень удобное расположение, от метро идти м...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Положительное место с хорошими блюдами , тольк...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Удобное расположение👍.  Работает круглосуточно...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Лучший шашлык в Звенигороде.\\nПриветливый и ве...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>Великолепное место, очень необычное. На террит...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>Одно из любимых мест в Москве.здесь осень атмо...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>Самый любимый ресторан, вмещающий в себя насто...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>Всегда всё очень вкусно! Заказываем только мир...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>Отличное заведение. Раньше до ремонта было уют...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>172 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text\n",
       "0    Глубинка страны во всех своих проявлениях. Асс...\n",
       "2    Не очень удобное расположение, от метро идти м...\n",
       "5    Положительное место с хорошими блюдами , тольк...\n",
       "10   Удобное расположение👍.  Работает круглосуточно...\n",
       "12   Лучший шашлык в Звенигороде.\\nПриветливый и ве...\n",
       "..                                                 ...\n",
       "478  Великолепное место, очень необычное. На террит...\n",
       "483  Одно из любимых мест в Москве.здесь осень атмо...\n",
       "485  Самый любимый ресторан, вмещающий в себя насто...\n",
       "491  Всегда всё очень вкусно! Заказываем только мир...\n",
       "496  Отличное заведение. Раньше до ремонта было уют...\n",
       "\n",
       "[172 rows x 1 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tmp[['text']][thems == '2']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1fc852",
   "metadata": {},
   "source": [
    "## gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede5a32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(processed_data)\n",
    "corpus = [dictionary.doc2bow(l) for l in processed_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fe2e7f",
   "metadata": {},
   "source": [
    "# Метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcaa6abf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f01ee3a",
   "metadata": {},
   "source": [
    "# Сбор всего в Pipeline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
